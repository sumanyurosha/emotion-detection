{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "emotion_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanyurosha/emotion-detection/blob/master/emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh8tbVe1htu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne_Pp_VchtvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmTM-h8LiUz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "68ad0bf5-ef44-46a0-ee0e-b4fda240420a"
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "# Create a couple of workers\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  \n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 07:03:06.460136 140595261843328 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0818 07:03:06.479596 140595261843328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE1RBUt0htvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def covert_into_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,'wb'))\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Fd-DBmi3zQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d48c421c-006b-4677-8e1b-7724bf413eba"
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwr_zutrhtvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "27965f13-5853-4bf9-fd03-0190e726910a"
      },
      "source": [
        "#load data\n",
        "data = load_from_pickle(directory='/gdrive/My Drive/Resources/Dataset/emotion-detection/merged_training.pkl')\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fde3e42b4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERtf1/4EfnAP+MudQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_kDCyZhtvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e08063b-66e5-414f-bab8-67810b1f54fc"
      },
      "source": [
        "print(data.shape)\n",
        "print(type(data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(416809, 2)\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzwaTnchtvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "68870565-57e4-4dcc-a3f8-ce892b315a96"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27383</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110083</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140764</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100071</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2837</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "27383   i feel awful about it too because it s my job ...  sadness\n",
              "110083                              im alone i feel awful  sadness\n",
              "140764  ive probably mentioned this before but i reall...      joy\n",
              "100071           i was feeling a little low few days back  sadness\n",
              "2837    i beleive that i am much more sensitive to oth...     love"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDD3WA51htvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copying data with number of tokens less than 70\n",
        "data[\"token size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data[\"token size\"] < 70].copy()\n",
        "\n",
        "#sampling data\n",
        "data = data.sample(n=50000, replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3nzD7whtv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "28a20bf6-e0c4-460d-9e6e-9eb4bf33fea9"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAiMtuMnhtv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConstructDictionary():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2index = {}\n",
        "        self.index2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        \n",
        "        #creating tokens from sentences and adding them to dictionary\n",
        "        for sentence in self.sentences:\n",
        "            self.vocab.update(word_tokenize(sentence))\n",
        "            \n",
        "        #sorting the dictionary\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        \n",
        "        #adding padding token to 0 index\n",
        "        self.word2index['<pad>'] = 0\n",
        "           \n",
        "        #creating a word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2index[word] = index + 1         #adding 1 becuase of padding element at 0 index\n",
        "            \n",
        "        #creating a index to word mapping\n",
        "        for index, word in self.word2index.items():\n",
        "            self.index2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayaey_t4htwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e5809ca1-477a-464c-a609-1c98ca598fbb"
      },
      "source": [
        "inputs = ConstructDictionary(data[\"text\"].values.tolist())\n",
        "inputs.vocab[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aaron',\n",
              " 'abandoned',\n",
              " 'abba',\n",
              " 'abilities',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'abnormality',\n",
              " 'abortion',\n",
              " 'about']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZgGx3ghtwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "307af423-8c8d-4744-c036-f69b64fdf37f"
      },
      "source": [
        "len(inputs.vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8167"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1njUEuBQhtwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed9872e4-d754-428e-c85e-d5ee3ca5df9f"
      },
      "source": [
        "input_tensors = [[inputs.word2index[word] for word in word_tokenize(sentence) ] for sentence in data['text'].values.tolist() ]\n",
        "input_tensors[:2]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3485,\n",
              "  2591,\n",
              "  3624,\n",
              "  7332,\n",
              "  5573,\n",
              "  7339,\n",
              "  1,\n",
              "  5838,\n",
              "  4248,\n",
              "  8011,\n",
              "  2802,\n",
              "  6321,\n",
              "  7654,\n",
              "  4103,\n",
              "  703,\n",
              "  7665,\n",
              "  2947,\n",
              "  7189,\n",
              "  1075,\n",
              "  3530,\n",
              "  1780,\n",
              "  5595,\n",
              "  261,\n",
              "  8161,\n",
              "  3411],\n",
              " [3451,\n",
              "  2589,\n",
              "  513,\n",
              "  2735,\n",
              "  3310,\n",
              "  2534,\n",
              "  3400,\n",
              "  3422,\n",
              "  3310,\n",
              "  7981,\n",
              "  4675,\n",
              "  2589,\n",
              "  3400,\n",
              "  2249,\n",
              "  3310,\n",
              "  3911,\n",
              "  4675,\n",
              "  2589,\n",
              "  261,\n",
              "  2735,\n",
              "  7222,\n",
              "  6664,\n",
              "  7967,\n",
              "  4835,\n",
              "  3862,\n",
              "  2763,\n",
              "  4988,\n",
              "  7967,\n",
              "  3310,\n",
              "  2559,\n",
              "  3728,\n",
              "  261,\n",
              "  206,\n",
              "  7222,\n",
              "  4406,\n",
              "  443,\n",
              "  3747,\n",
              "  4835,\n",
              "  871,\n",
              "  7665,\n",
              "  3302,\n",
              "  261,\n",
              "  4113,\n",
              "  3235,\n",
              "  2811,\n",
              "  6191,\n",
              "  5156,\n",
              "  390,\n",
              "  7921]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXxqSUVhtwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7A6E0gIhtwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4a296cc-683e-4db2-cdb5-6f9cd7b29155"
      },
      "source": [
        "max_length_input = max_length(input_tensors)\n",
        "print(max_length_input)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLLtdK88htwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len=max_length_input):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVekMjUKhtwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c455c557-14fd-42cf-bdd1-e9d6ff1e8c6d"
      },
      "source": [
        "input_tensors = [pad_sequences(x, max_length_input) for x in input_tensors]\n",
        "input_tensors = \n",
        "input_tensors[:2]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3485, 2591, 3624, 7332, 5573, 7339,    1, 5838, 4248, 8011, 2802,\n",
              "        6321, 7654, 4103,  703, 7665, 2947, 7189, 1075, 3530, 1780, 5595,\n",
              "         261, 8161, 3411,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0]),\n",
              " array([3451, 2589,  513, 2735, 3310, 2534, 3400, 3422, 3310, 7981, 4675,\n",
              "        2589, 3400, 2249, 3310, 3911, 4675, 2589,  261, 2735, 7222, 6664,\n",
              "        7967, 4835, 3862, 2763, 4988, 7967, 3310, 2559, 3728,  261,  206,\n",
              "        7222, 4406,  443, 3747, 4835,  871, 7665, 3302,  261, 4113, 3235,\n",
              "        2811, 6191, 5156,  390, 7921,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJzGHvyRhtw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we are using transforming our target values using one-hot encoding\n",
        "\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "\n",
        "data_labels = [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1sm89-Khtw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0faf7902-593d-474d-fcab-e4e074356196"
      },
      "source": [
        "target_tensor[:2]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJoH_SIhtxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "ae816aa0-0e60-4f7b-cc3a-bc3a93b0fcb5"
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131152</th>\n",
              "      <td>im feeling inspired to pull together a relaxed...</td>\n",
              "      <td>joy</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28212</th>\n",
              "      <td>i feel badly for his family how humiliated his...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token size\n",
              "131152  im feeling inspired to pull together a relaxed...      joy          25\n",
              "28212   i feel badly for his family how humiliated his...  sadness          49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sg2_4mvhtxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emotion(x):\n",
        "    return np.argmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dOo1JfThtxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fc788d1-c01f-4cf7-9de1-f5b3ad56ebaf"
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5vkesnMhtxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5azl83WJhtx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f8f04c6-177e-46da-c8fe-ee379ab71d88"
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'joy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkAKaQ9Ohtx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9445042e-fdd8-44b1-c013-e1779280dc7e"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensors, target_tensor, test_size=0.2)\n",
        "\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 40000, 5000, 5000, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbM3x4v8htyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2index)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixHQIf5nhtyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ffJwLzhtyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRmE0hXAtXBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3294074-e5ba-4a83-e9e7-30ee346d1d2f"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "syft.frameworks.torch.tensors.interpreters.native.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amr8h84ttAv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cH5v6JvhtyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = sy.BaseDataset(input_tensor_train, target_tensor_train).federate((alice,bob))\n",
        "val_dataset = sy.BaseDataset(input_tensor_val, target_tensor_val).federate((alice,bob))\n",
        "test_dataset = sy.BaseDataset(input_tensor_test, target_tensor_test).federate((alice,bob))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "federated_train_loader = sy.FederatedDataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "federated_val_loader = sy.FederatedDataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "federated_test_loader = sy.FederatedDataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udCamEpjhtyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "717958b3-eeb3-45e8-82c0-d93f7c2b2a8c"
      },
      "source": [
        "input, labels = next(iter(train_dataset))\n",
        "print(input[0].get(), labels[0].get())"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3451, 2053, 7085, 6156, 3747, 2735, 6720, 4878,  261, 3451, 2053, 7085,\n",
            "        2589, 3591,   10,  629, 5207, 8011, 2968,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0], device='cpu') tensor([0, 0, 0, 0, 1, 0], device='cpu')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvWr6JoNxDiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dNkVDtDxKIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWYN-1RVxQQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "#xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", x.size())\n",
        "\n",
        "output, _ = model(x.to(device), device)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epSEEYlBxVV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}