{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def covert_into_pickle(item, directory):\n",
    "    pickle.dump(item, open(directory,'wb'))\n",
    "\n",
    "def load_from_pickle(directory):\n",
    "    return pickle.load(open(directory,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29508180748>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data\n",
    "data = load_from_pickle(directory='C:/Users/Sumanyu/Code/emotion-detection/merged_training.pkl')\n",
    "data.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416809, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotions\n",
       "27383   i feel awful about it too because it s my job ...  sadness\n",
       "110083                              im alone i feel awful  sadness\n",
       "140764  ive probably mentioned this before but i reall...      joy\n",
       "100071           i was feeling a little low few days back  sadness\n",
       "2837    i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying data with number of tokens less than 70\n",
    "data[\"token size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
    "data = data.loc[data[\"token size\"] < 70].copy()\n",
    "\n",
    "#sampling data\n",
    "data = data.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sumanyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstructDictionary():\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.vocab = set()\n",
    "        self.create_index()\n",
    "        \n",
    "    def create_index(self):\n",
    "        \n",
    "        #creating tokens from sentences and adding them to dictionary\n",
    "        for sentence in self.sentences:\n",
    "            self.vocab.update(word_tokenize(sentence))\n",
    "            \n",
    "        #sorting the dictionary\n",
    "        self.vocab = sorted(self.vocab)\n",
    "        \n",
    "        #adding padding token to 0 index\n",
    "        self.word2index['<pad>'] = 0\n",
    "           \n",
    "        #creating a word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2index[word] = index + 1         #adding 1 becuase of padding element at 0 index\n",
    "            \n",
    "        #creating a index to word mapping\n",
    "        for index, word in self.word2index.items():\n",
    "            self.index2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aaaaaaaall',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abby',\n",
       " 'abdomen',\n",
       " 'abefc',\n",
       " 'abel']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = ConstructDictionary(data[\"text\"].values.tolist())\n",
    "inputs.vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8196"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3574,\n",
       "  4877,\n",
       "  2683,\n",
       "  3468,\n",
       "  271,\n",
       "  825,\n",
       "  979,\n",
       "  3539,\n",
       "  4146,\n",
       "  3392,\n",
       "  3413,\n",
       "  4996,\n",
       "  4722,\n",
       "  789,\n",
       "  414,\n",
       "  3557,\n",
       "  3374,\n",
       "  5784,\n",
       "  7363,\n",
       "  1976,\n",
       "  3854,\n",
       "  7376,\n",
       "  8167,\n",
       "  7241,\n",
       "  3539,\n",
       "  8105,\n",
       "  2738,\n",
       "  4847,\n",
       "  695,\n",
       "  4302,\n",
       "  7980,\n",
       "  3374,\n",
       "  4003,\n",
       "  4722,\n",
       "  4206,\n",
       "  3851,\n",
       "  8175,\n",
       "  3539,\n",
       "  7283,\n",
       "  4959,\n",
       "  3539,\n",
       "  4785,\n",
       "  7363,\n",
       "  3581,\n",
       "  8167,\n",
       "  3624,\n",
       "  5027,\n",
       "  7363,\n",
       "  3022,\n",
       "  4960],\n",
       " [3539,\n",
       "  2680,\n",
       "  731,\n",
       "  7963,\n",
       "  1096,\n",
       "  1228,\n",
       "  721,\n",
       "  7982,\n",
       "  5053,\n",
       "  2622,\n",
       "  3024,\n",
       "  7374,\n",
       "  979,\n",
       "  8159,\n",
       "  4722,\n",
       "  2622,\n",
       "  3826,\n",
       "  4847,\n",
       "  7982,\n",
       "  7363,\n",
       "  601,\n",
       "  2875]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors = [[inputs.word2index[word] for word in word_tokenize(sentence) ] for sentence in data['text'].values.tolist() ]\n",
    "input_tensors[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "max_length_input = max_length(input_tensors)\n",
    "print(max_length_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x, max_len=max_length_input):\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    padded[:len(x)] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3574, 4877, 2683, 3468,  271,  825,  979, 3539, 4146, 3392, 3413,\n",
       "        4996, 4722,  789,  414, 3557, 3374, 5784, 7363, 1976, 3854, 7376,\n",
       "        8167, 7241, 3539, 8105, 2738, 4847,  695, 4302, 7980, 3374, 4003,\n",
       "        4722, 4206, 3851, 8175, 3539, 7283, 4959, 3539, 4785, 7363, 3581,\n",
       "        8167, 3624, 5027, 7363, 3022, 4960,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0], dtype=int64),\n",
       " array([3539, 2680,  731, 7963, 1096, 1228,  721, 7982, 5053, 2622, 3024,\n",
       "        7374,  979, 8159, 4722, 2622, 3826, 4847, 7982, 7363,  601, 2875,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0], dtype=int64)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors = [pad_sequences(x, max_length_input) for x in input_tensors]\n",
    "input_tensors[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are using transforming our target values using one-hot encoding\n",
    "\n",
    "emotions = list(set(data.emotions.unique()))\n",
    "num_emotions = len(emotions)\n",
    "\n",
    "mlb = preprocessing.MultiLabelBinarizer()\n",
    "\n",
    "data_labels = [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
    "bin_emotions = mlb.fit_transform(data_labels)\n",
    "target_tensor = np.array(bin_emotions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(x):\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emotion(target_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {0:'anger', 1:'love', 2:'joy', 3:'sadness', 4:'fear', 5:'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict[get_emotion(target_tensor[0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
